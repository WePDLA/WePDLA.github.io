---
layout: post
mathjax: true
catalog: true
comments: true
top-tags-list: true
header-img: "img/post-bg-universe.jpg"
header-mask: 0.4
title: 流水线并行论文集
subtitle: 流水线并行论文集总结
author: 唐宇
tags: [ 流水线并行]
---



# PP论文集

## Gpipe论文笔记

Gpipe核心如图所示：

{% include figure.html src="/figures/PP-papers/gpipe.png" caption="图1：Gpipe。"%}

### Problem
1、模型容量（model capacity）增加但是受限于GPU的内存，而且目前的方法受限于特殊的架构；
2、模型并行算法设计和实现比较困难，需要算法设计人员在缩放度、灵活性和训练效率中做出抉择；


### KeyInsight

1、Gpipe把模型划分成``K``个单元，然后分别对应地放在``K``个加速器上（GPU），然后一系列的通信原语自动在这些单元中进行操作。（<font color=purple>这个地方的通信原语是all_reduce?</font>）通过<font color=red>同步通信时间</font>来保证所有单元之间的评估loss。
2、在前向过程中，batchsize ``N``均分为``M``个micro-batches，这``M``个micro-batches在``K``个加速器中进行流水线并行。
3、反向过程，每一个micro-batch的梯度根据前向过程中使用的相同的模型参数进行计算，在mini-batch结束之后，所有的``M``个micro-batch计算出来的梯度需要做一次<font color=orange>梯度累加</font>.（<font color=orange>gradient accumulation</font>，<font color=red>这一点极为重要，不然可能会导致训练不收敛</font>。<font color=purple>类似的还有比如在pytorch做DDP的时候，在做参数更新之前要做gradient average</font>）。
如果网络层中有BN，必要时，在每个micro-batch和副本上计算训练期间输入的足够统计数据。(<font color=purple>也就是像ResNet这样的网络需要输入足够的训练数据？</font>)

### 性能评估

在前向过程中，每个GPU实际上只保存单元边界的输出激活；反向过程，第``k``个GPU重新计算复合前向函数（compose forward function）。(<font color=purple>这个复合前向函数不是很懂，另外这个跟重计算好像不太一样，因为在重计算中是抛弃了前向过程中的activation的</font>)峰值的内存需求减少到了``O(N+\frac{L}{K} × \frac{N}{M})``，\frac{L}{K}是划分的单元个数，\frac{N}{M}是micro-batchsize。原来内存需求是``O(N×L)``的。

### 个人分析
Gpipe最大的问题应该是在流水线中的bubble，这个问题在之后Pipedream中得到了比较好的解决，主要是1F1B策略的使用。
还有一个问题是过多的通信原语吧，有很多的通信操作，造成通信时间过长。

<div style='display: none'>
    我是注释，不会在浏览器中显示。
    我是注释。
</div>

## PipeDream论文笔记
PipeDream的论文发表在SOSP上面。全称：PipeDream: Generalized Pipeline Parallelism for DNN Training

### Problem 
1、当前的pipeline parallel的方法（Gpipe）有一个致命的缺点：GPU低使用效率，看图1可以看出来Gpipe中有很大的bubble，GPU使用效率肯定低；
2、Gpipe为了提高使用效率，把mini-batch改成了micro-batch，在GPU中进行流水，但是这样频繁的流水线更新（pipeline flushes）降低了硬件的效率；
3、流水线并行还有一个与生俱来的缺点就是：吞吐量取决于流水线中最慢的状态，因而所有的状态划分的时候要尽量保证计算时间相同。

### KetInsight 
文章的KeyInsight可以分为三个部分，分别对PP中的三个challenge进行分析和解决。
* 挑战1、模型划分问题：要保证有一个比较好的吞吐量。在PP中吞吐量取决于最慢的stage。
  解决办法：PipeDream均等划分，近似均等，保证每个stage以一个近似相同的速度完成计算。
* 挑战2、模型在流水线中的调度问题：做forward的工作节点需要把计算结果传送给下游的工作节点；计算backward的节点需要把结果传给上游节点
  解决办法：在开始阶段，input stage需要足够多的数据来保证在steady state中的流水线全部利用到；在steady state的时候，每个stage在minibatch中执行forward和backward的时候做反复交替，也就是<font color=orange>1F1B</font>。<font color=purple>这里说backward计算时间大概是forward的两倍，个人不是很懂？</font>

  {% include figure.html src="/figures/PP-papers/pipedream.png" caption="图2：PipeDream。"%}

* 挑战3、怎么训练才能有效：在PipeDream的图中可以看出在minibatch 5计算forward是在minibatch 1的backward结束之后开始计算的，5的backward计算则需要2、3、4的backward结束之后才开始，所以<font color=blue>5在stage 1计算梯度是和forward过程完全不一样的权重</font>，这种差异可能导致训练不收敛.
  解决办法：<font color=orange>权重储存（weight stashing）</font>解决权重不匹配的问题。保存多个版本的权重，每一个活跃的minibatch都有一个保存，每个stage使用最新保存下来的权重；
  {% include figure.html  height="652" width="488" src="/figures/PP-papers/weightstashing.png" caption="图3：Pipedream中的weightstashing。"%}

  <font color=orange>垂直同步（Vertical Sync）</font>，在stage之间的一个方法，梯度不会在系统中的所有minibatch上聚合——垂直同步只是确保使用相同的权重版本来计算不同worker之间的梯度（但应用梯度的权重版本与用于计算的权重版本不同）。
  
### 个人分析
1、PipeDream最大的idea就是1F1B，思路比较简单就是及时对minibatch做backward，不等待其他的stage，解耦stage之间的依赖关系。
2、<font color=purple>保存不同版本的weight会不会造成内存的冗余？</font>
3、有关<font color=purple>通信没有比较明确的分析？</font>，但是流水线的flush应该是减少了。

## Dapple：A Pipelined Data Parallel Approach for Training Large Models

### Problem 
1、DP要做梯度同步，对于<font color=blue>要实现线性缩放，梯度同步是一个很严重的问题</font>，虽然有梯度累加、计算和通信overlap这样的方法，DP在large batchsize的情况下，模型微调更难。(<font color=purple>也就是说对于LARS和LAMB这样的方法，模型微调很难？</font>)
2、同步PP在训练迭代更新时也需要梯度同步，同样导致阻碍了线性缩放。为了尽可能地最大化设备使用率，如果尽量多的使用PP的stage的话将导致严重的内存消耗，同样的，同步训练内存消耗也很严重，比如Gpipe，在训练中的bubble导致GPU利用率不高，设备浪费；
3、PP的另一个问题时对于<font color=blue>stage的调度</font>，<font color=purple>这个问题应该是PP中一直存在并且亟需解决的一个问题，目前的方法没有最优的，都是在之前的工作上进行改进的</font>，<font color=red>PP中最优的schedule或许是一个可以研究的地方</font>

### KeyInsight
同步PP要解决的两个核心问题：
* 额外的内存消耗；
* 冗余的计算
{% include figure.html  height="652" width="488" src="/figures/PP-papers/dapple.png" caption="图4：Dapple。"%}

DAPPLE：包含一个profiler、planner、runtime
* Profiler：输入一个DNN模型，然后对每个层的执行时间、激活的大小、参数大小进行profile；~~（<font color=purple>个人觉得这个部分在模型训练中没有必要，不过是为了进行profile。</font>)~~
* Planner：planner把profiling的结果作为输入，然后根据global batchsize生成一个优化的并行策略，planner要<font color=orange>最小化每次迭代的执行时间</font>；
* Runtime：runtime把planner的输出作为输入并把原始的计算图转化为一个流水线并行图，global batchsize分割为micro-batch并做调度。

{% include figure.html src="/figures/PP-papers/gpipevsdapple.png" caption="图5：gpipe vs dapple。"%}


### DAPPLE的Schedule策略：提前进行backward scheduling

1、Gpipe一次把M个micro-batch都丢进pipeline，DAPPLE在开始的时候丢K（K<M）个micro-batch然后及时释放内存
2、在一个micro-batch进行FW之后就进行BW保证BW可以及时调度
<font color=blue>DAPPLE在开始阶段内存增加</font>

### DAPPLE planner

### DAPPLE runtime
#### 步骤：
1、首先给每个stage建立一个forward/backward的计算图
2、在相邻阶段之间引入额外的 split/concat 节点以进行激活通信（<font color=purple>通信方式</font>）
3、建立子图，在同步训练的时候进行权重更新

#### stage之间通信
DAPPLE复制了一些阶段，使得运行一个阶段的节点数量在相邻阶段之间可以不同，并且它们之间的通信模式不同于直接流水线设计。（<font color=purple>复制阶段会造成内存冗余？</font>）

## Xpipe

### Problem 
1、同步训练固有的问题，训练的效率比较低，设备使用率不高，而且在梯度同步的时候阻碍了线性的缩放；
2、由于多个micro-batch的交叉训练，Asynchronous model training（AMP）面临严重的权重不一致和陈旧(staleness)问题，权重陈旧的问题使收敛变的缓慢，降低了模型的准确度；
3、PipeDream采用的不同的version的weight，一方面会有内存冗余。

{% include figure.html src="/figures/PP-papers/Xpipe.png" caption="图6：Xpipe。"%}

### KeyInsight
1、Xpipe在一整个minibatch中的T个micro-batch权重是共享的；
2、每个mini-batch分配一个bellwether对权重预测进行管理，它总是首先在T个micro-batch之间执行前向和后向传递
3、定义权重差异（weight difference）衡量权重更新的数量
{% include figure.html src="/figures/PP-papers/weight_diff.png" caption="图7：weight difference的计算。"%}

## PipeMare

## TorchGpipe

### Problem
1、Gpipe计算图中有依赖（<font color=purple>PP中的计算依赖不可避免</font>）

## HetPipe

[paper](https://www.usenix.org/conference/atc20/presentation/park)

集成了PP和DP，主要关注点在训练系统中存在异构GPU的情况。

### KeyInsight

HetPipe的系统架构如下：
{% include figure.html src="/figures/PP-papers/hetpipe-1.png" caption="图1：HetPipe的系统架构。"%}

VW: Virtual Worker。
简言之，HetPipe是DP和PMP两种并行方式的综合，每一个VW在系统中的角色相当于常规意识中DP的worker，在这些VW之间进行数据并行，故而叫做Virtual Worker。在每个Virtual Worker内部执行PMP，执行流水线并行。从宏观来看，进行数据并行的系统结构是传统的参数服务器架构。

跟传统的参数服务器类似，server用来更新全局的模型参数。那么在HetPipe之间就会有两种staleness存在，一种是local staleness，另一种是global staleness。显然，这两种staleness分别表示的时候在VW之内的权重阻塞和整个系统中的权重阻塞。

对于HetPipe，作者提出了Wave Synchronous Parallel（WSP）进行权重同步，并且定义*wave*：在一个virtual worker中同时执行的minibatch序列。在同一个*wave*中minibatch用到的权重是没有依赖的。一个wave相当于一个clock，以wave为单位进行数据的push和pull。
{% include figure.html src="/figures/PP-papers/hetpipe-2.png" caption="图1：HetPipe的PP执行过程。"%}

HetPipe和PipeDream都有一个权重更新时机的问题，在PipeDream中采用的方式是weight stashing。而在HetPipe中，权重在层与层之间是不进行更新的。当virtual worker开始处理一个新的minibatch的时候，利用local权重的最新值而不等待其他minibatch更新之后的权重。从理论上来看，这样是可以确认训练过程收敛的，有一个类似的工作是使用delayed的权重进行更新（DDG）。简言之在HetPipe中就是有啥权重就用啥权重。


### Pros and cons 

1、这篇文章把PMP和DP集成到了一起，提出来一种针对系统异构GPU情况下的流水线并行方式。在流水线并行中主要存在的权重更新问题通过一种看似lazy的方式来进行，从理论上来说是可以收敛的。更重要的是提出来了针对PMP的收敛性分析思路和方式。

2、但是针对异构的GPU而言，如果采用DP或者MP的方式，应该是存在最短木板问题的，要适应整个系统中显存最小的卡。
计算是考虑了，local staleness和global staleness就是针对这样考虑的，而且使用当前权重不等待更新也是考虑了这样的问题。

3、从整个系统层面来看，实际上就是参数服务器架构，也就自然而然的继承了PS中的优点和缺点。

4、还有个问题就是在训练中的batchsize，是按照木桶原理来计算还是不同的GPU会有不同的batchsize呢？

## 几种PP的比较

| 方法        | 同步/异步 | 优点  | 缺点  | 方式总结 |
|:---------:|:-----:|:---:|:---:|
| Gpipe     | 同步    |  首个PP方法，比传统的MP效率要高   |    schdedule方式需要改进，存在大量bubble | |
| PipeDream | 异步    |  1F1B调度策略，异步并行的方式，改进了Gpipe大量bubble的问题   | 不同version的weight，内存有冗余    |   |
| DAPPLE    | 同步    |  schedule策略较好   |  通信未知，感觉通信量是一个大问题   |   |
| Xpipe     | 异步    |  权重预测，加速收敛   |  内存消耗比较大，没有好的schedule的策略  |  |
| HetPipe   | 同步    |  使用及时权重，收敛性分析   | PS的基础架构，木桶原理  | PP+DP   | 




<font color=red>PP的固有问题:</font>

- schedule策略
- 通信
- 收敛
- 内存占用（设备使用率）


