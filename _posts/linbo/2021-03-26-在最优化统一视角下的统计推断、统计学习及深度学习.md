---
layout: post
mathjax: true
catalog: true
comments: true
top-tags-list: true
header-img: "img/post-bg-universe.jpg"
header-mask: 0.4
title: 在最优化统一视角下的统计推断、统计学习及深度学习
subtitle: 机器学习与最优化方法
author: 乔林波、刘睿
tags: [机器学习, 最优化]
---


在最优化的视角下，机器学习的多个分支可以有效统一，比如：统计推断、统计学习与深度学习。


#  一、统计推断

统计推断中核心任务为：假设有观测的数据集为 $\mathcal O =\{x_i\}, i=[1, 2, \cdots, n]$，需要由观测数据推断出最优模型参数$\mathcal P=\{\mu\}$。
根据假设的不同，统计推断可以分为两个学派，频率学派和贝叶斯学派。
频率学派的观点是仅使用数据的条件分布，不承认先验概率。
贝叶斯学派的观点是综合利用先验信息和样本信息。
可以认为，频率学派观点是贝叶斯学派观点的一个特例。

## 1.1 统计推断一般范式

对于频率学派，认为$\mathcal P=\{\mu\}$是某个确定的实数，使用最大似然或最大对数似然进行统计推断。
对于贝叶斯学派，认为 $\mathcal P$ 符合某一先验分布，结合先验分布，使用最大后验估计或最大对数后验估计进行统计推断，其中，通过不同的先验分布可以推导出不同的模型。

综合频率学派和贝叶斯学派，假设随机变量$X$服从高斯分布，方差$\delta^2=1$：\[
X \sim P(x|\mathcal P) = \frac{1}{\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2}},
\]

推断最优模型参数也即最大化如下问题：

\begin{equation}
\displaystyle \max_{\mu \in (-\infty, +\infty)} \log P(\mathcal O | \mathcal P) P(\mathcal P).\tag{1}
\end{equation}

具体说来，推断过程如下：

## 1.2 频率学派统计推断

对于频率学派，认为$\mathcal P=\{\mu\}$是某个确定的实数，直接有：
\begin{equation}
\begin{array}{cl}
\displaystyle \max_{\mu \in (-\infty, +\infty)} f(\mu) &= \max_{\mu \in (-\infty, +\infty)} \log P(\mathcal O | \mathcal P) \\\\ 
  & = \displaystyle \max_{\mu \in (-\infty, +\infty)} \log \left(  \prod_{i=1}^n P( x_i \in \mathcal O | \mathcal P)\right) \\\\ 
  & = \displaystyle \max_{\mu \in (-\infty, +\infty)} \log  \left( (\frac{1}{\sqrt{2\pi}})^n e^{-\frac{\sum_{i=1}^n(x_i -\mu)^2 }{2}}\right)  \\\\ 
  & = -\displaystyle \max_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2 + n\log \sqrt{2\pi}\right)  
\tag{2} \label{prob-fre}
\end{array}
\end{equation}

## 1.3 贝叶斯学派统计推断（高斯分布）

对于贝叶斯学派，认为 $\mathcal P$ 符合某一先验分布，在假设为高斯分布$\mathcal P=\{\mu\}, \mu \sim \mathcal N(0, \delta_0^2)$时，有：
\begin{equation}
\begin{array}{cl}
\displaystyle \max_{\mu \in (-\infty, +\infty)} f(\mu) &= \displaystyle \max_{\mu \in (-\infty, +\infty)} \log P(\mathcal O | \mathcal P) P(\mathcal P)\\\\ 
& = \displaystyle \max_{\mu \in (-\infty, +\infty)} \log \left( \prod_{i=1}^n P( x_i \in \mathcal O | \mathcal P) P(\mathcal P)\right)  \\\\ 
& = \displaystyle \max_{\mu \in (-\infty, +\infty)}  \log \left( \left( (\frac{1}{\sqrt{2\pi}})^n e^{-\frac{\sum_{i=1}^n(x_i -\mu)^2 }{2}}\right) (\frac{1}{\sqrt{2 \pi} \delta_0}) e^{-\frac{\mu^2}{2\delta_0^2}} \right) \\\\ 
& = -\displaystyle \max_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2 + n\log \sqrt{2\pi} + \frac{1}{2 \delta_0^2}\mu^2 + \log{\sqrt{2 \pi}} \delta_0\right)  
\tag{3}\label{prob-b-norm}
\end{array}
\end{equation}

## 1.4 贝叶斯学派统计推断（拉普拉斯分布）

对于贝叶斯学派，认为 $\mathcal P$ 符合某一先验分布，在假设为拉普拉斯分布$\mathcal P=\{\mu\}, \mu \sim \mathcal L(0, \delta_0^2)$时，有：
\begin{equation}
\begin{array}{cl}
\displaystyle \max_{\mu \in (-\infty, +\infty)} f(\mu) &= \displaystyle \max_{\mu \in (-\infty, +\infty)} \log P(\mathcal O | \mathcal P) P(\mathcal P)\\\\ 
& = \displaystyle \max_{\mu \in (-\infty, +\infty)} \log \left( \prod_{i=1}^n P( x_i \in \mathcal O | \mathcal P) P(\mathcal P)\right)  \\\\ 
& = \displaystyle \max_{\mu \in (-\infty, +\infty)}  \log \left( \left( (\frac{1}{\sqrt{2\pi}})^n e^{-\frac{\sum_{i=1}^n(x_i -\mu)^2 }{2}}\right) (\frac{1}{2 \delta_0^2}) e^{-\frac{|\mu|}{\delta_0^2}} \right)  \\\\ 
& = -\displaystyle \max_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2 + n\log \sqrt{2\pi} + \frac{1}{\delta_0^2} |\mu| + \log 2 \delta_0^2\right)
\tag{4}\label{prob-b-lap}
\end{array}
\end{equation}

## 1.5 贝叶斯学派统计推断（拉普拉斯和高斯混合分布）

对于贝叶斯学派，认为 $\mathcal P$ 符合某一先验分布，在假设为拉普拉斯和高斯混合分布$\mathcal P=\{\mu\}, \mu \sim \mathcal M(0, \delta_{0,1}^2, \delta_{0,2}^2)$时，有：
\begin{equation}
\begin{array}{cl}
\displaystyle \max_{\mu \in (-\infty, +\infty)} f(\mu) &= \displaystyle \max_{\mu \in (-\infty, +\infty)} \log P(\mathcal O | \mathcal P) P(\mathcal P)\\\\ 
& = \displaystyle \max_{\mu \in (-\infty, +\infty)} \log \left( \prod_{i=1}^n P( x_i \in \mathcal O | \mathcal P) P(\mathcal P)\right)  \\\\ 
& = \displaystyle \max_{\mu \in (-\infty, +\infty)}  \log \left( \left( (\frac{1}{\sqrt{2\pi}})^n e^{-\frac{\sum_{i=1}^n(x_i -\mu)^2 }{2}}\right) 
(2\sqrt{2\pi}\delta_{0,1}^2\delta_{0,2} )^{-1} e^{-\frac{|\mu|}{\delta_{0,1}^2}-\frac{\mu^2}{2\delta_{0,2}^2}} \right)\\\\ 
& = -\displaystyle \max_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2 + n\log \sqrt{2\pi} + \frac{1}{\delta_{0,1}^2} |\mu| + \frac{1}{2\delta_{0,2}^2} \mu^2+ \log (2\sqrt{2\pi}\delta_{0,1}^2\delta_{0,2} )\right)
\tag{5}\label{prob-b-lap-norm}
\end{array}
\end{equation}

## 1.6 统计推断优化求解

寻求最大概率的过程也即求解极大对数似然或极大对数后验估计，对于上述不同的统计推断，有：

求解Prob. \eqref{prob-fre} 等价于求解线性规划问题：
\begin{equation}
\displaystyle \min_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2\right) 
\tag{6}\label{opt-prob-fre}
\end{equation}

求解Prob. \eqref{prob-b-norm} 等价于求解岭回归问题：
\begin{equation}
\displaystyle \min_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2\right) + \frac{1}{2 \delta_0^2}\mu^2
\tag{7}\label{opt-b-norm}
\end{equation}

求解Prob. \eqref{prob-b-lap} 等价于求解Lasso问题：
\begin{equation}
\displaystyle \min_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2\right) + \frac{1}{\delta_0^2} |\mu| 
\tag{8}\label{opt-b-lap}
\end{equation}

求解Prob. \eqref{prob-b-lap-norm} 等价于求解弹性网问题:
\begin{equation}
\displaystyle \min_{\mu \in (-\infty, +\infty)} \left(\frac{1}{2} \sum_{i=1}^n (x_i -\mu)^2\right) + \frac{1}{\delta_{0,1}^2} |\mu| + \frac{1}{2\delta_{0,2}^2} \mu^2
\tag{9}\label{opt-b-lap-norm}
\end{equation}

模型求解见 Sec~\eqref{sec-opt}。



# 二、统计学习

一般学习问题中，核心任务是：假设有观测数据集为 $\xi =\{(x_i,y_i)\}_{i=1}^n$， 需要从拟合函数集合$\mathcal F$中选取最优拟合函数$f(x;\mu)=y$，其中，$f\in \mathcal F, (x,y)\in \xi, x=[x_1, x_2, \cdots, x_n]$为观测数据，$y=[y_1, y_2, \cdots, y_n]$ 为相应的标签。

## 2.1 学习问题一般范式

学习问题一般可以表示为最小化风险函数。一般先构造损失函数$l(\mu;\xi)$为获得最优拟合函数，也即最小化损失函数的期望：

$
\min_\mu \mathbb R(\mu)=E[l(\mu;\xi)]=\int l\left(y, f(x;\mu)\right) dF(x,y),
\tag{10}\label{prob-rm}
$

其中，$l(y, f(x;\mu))$ 为损失函数，$F(x,y)$为观测数值对的联合分布。
在实际问题中，联合分布在学习过程中往往未知，直接最小化风险函数并不具有可操作性。于是，最小化风险函数$R(x)$一般被替换为最小化经验风险函数$R^*(x)$：

$
\displaystyle \min_\mu R^*(\mu)=\frac{1}{n}\sum_{i=1}^n l(y_i, f(x_i;\mu)) = l(Y, f(X;\mu)),
\tag{11}\label{prob-erm}
$

其中，$X=[x_0, x_1, \cdots, x_n],~Y=[y_0, y_1, \cdots, y_n]$。

## 2.2 线性回归

假设$f(X;\mu)=X\mu$，定义损失函数$l(\mu;\xi) = \frac{1}{2}\|X\mu-Y\|^2$，
构造线性规划模型，也即：

$
\min_\mu \frac{1}{2}\|X\mu-Y\|^2.
\tag{12}\label{prob-ml-linear}
$

可得，$\mu= (X^\top X)^{-1} X^\top Y$。
模型求解见 Sec~\ref{sec-opt}。

## 2.3 岭回归

假设$f(X;\mu)=X\mu$，定义损失函数$l(\mu;\xi) = \frac{1}{2}\|X\mu-Y\|^2$，
同时假设$\mu$，添加正则项 $\frac{\lambda}{2}\|\mu\|^2$，也即：

$
\min_\mu \frac{1}{2}\|X\mu-Y\|^2+\frac{\lambda}{2}\|\mu\|^2.
\tag{13}\label{prob-ml-reg}
$

可得，

\[
\mu= (X^\top X + \lambda I)^{-1} X^\top Y
\]

这里的$\lambda I$也即岭。
模型求解见 Sec~\ref{sec-opt}。

## 2.4 Lasso

假设$f(X;\mu)=X\mu$，定义损失函数$l(\mu;\xi) = \frac{1}{2}\|X\mu-Y\|^2$，
同时假设模型参数是稀疏的，添加正则项$\lambda|\mu|$，也即：

$
\min_\mu \frac{1}{2}\|X\mu-Y\|^2+\lambda|\mu|.
\tag{14}\label{prob-ml-lasso}
$

模型求解见 Sec~\ref{sec-opt}。

## 2.5 弹性网络

假设$f(X;\mu)=X\mu$，定义损失函数$l(\mu;\xi) = \frac{1}{2}\|X\mu-Y\|^2$，
同时添加正则$\lambda (\frac{\rho}{2}\|\mu\|^2 + (1-\rho) |\mu|)$，也即：

$
\min_\mu \frac{1}{2}\|X\mu-Y\|^2 + \lambda \left(\frac{\rho}{2}\|\mu\|^2 + (1-\rho) |\mu| \right).
\tag{15}\label{prob-ml-ela}
$

模型求解见 Sec~\ref{sec-opt}。


# 三、深度学习

最近，深度学习是学习问题一个备受关注的分支。
深度学习，或深度神经网络模型与传统统计学习有密切联系。从线性回归，经过多层嵌套可以构建一个简单的深度神经网络。
学习问题一般可以形式化为：

\[
\min_\mu l(Y, f(X;\mu)),
\]

线性回归中，$f(X;\mu) = X\mu$。

训练过程中，模型参数通过 Eq~\ref{SGD} 更新得到。由于模型的梯度没有解析解，于是一个自然而然的想法就是结合神经网络结构，利用链式法则，通过反向传播（BP）获得各个参数的梯度。
反向传播的一个简单例子是：

```python
# -*- coding: utf-8 -*-
import torch
import math

# Create Tensors to hold input and outputs.
x = torch.linspace(-math.pi, math.pi, 2000)
y = torch.sin(x)

pindx = torch.tensor([1, 2, 3])
xx = x.unsqueeze(-1).pow(pindx)

w = torch.ones((3), requires_grad=True)
b = torch.ones((1), requires_grad=True)

learning_rate = 1e-3

for i in range(20):
    z0 = torch.mv(xx,w)
    z1 = z0 + b
    sq = (z1-y)*(z1-y)
    loss = 0.5*torch.mean(sq)

    parameters = [w, b]  # z0, z1, sq, loss are not parameters.
    for p in parameters:
        if p.grad is not None:
            p.grad.zero_()

    loss.backward()

    for p in parameters:
        if p.grad is not None:
            p.data -= learning_rate*p.grad
    
    print('loss: ', loss.data)
```

示例代码中，更新模型参数的操作为梯度下降算法：“p.data -= learning_rate*p.grad”，简单有效，而参数 w、b 的梯度则是通过 loss.backward( )反向传播得到。
在后面关于神经网络的post里面，再具体拆解这个backward()及其核心的 autograd。


# 四、最优化方法

$\tag{sec-opt}\label{sec-opt}$

最优化方法关注于最小化目标函数:

\[
\min_x f(x),
\]

其中，决策变量$x \in \mathbb R^{M}$。

实际问题中，最优化问题$\min_x f(x)$基本没有直接的闭式解析解，一般采用迭代求解方式得到原问题最优解：

\[
x^{k+1} = x^k - \nabla f(x^k)
\]

## 3.1 随机梯度下降法

在大规模数据集驱动的机器学习问题中，数据集$A \in \mathbb R^{N \times M}$的数量很大，维度很高，带来巨大的内存开销，使得原始的全梯度下降法无法在普通计算平台上运行。
为了解决这类问题，一般构造随机梯度下降算法，每次仅用小批量数据$\{\xi_i=(a_i,b_i)\}$来更新模型参数 x：

$
x^{k+1} = x^k - \nabla f(x^k;\xi_i)
\tag{SGD}\label{SGD}
$

其中，$\{\xi_i=(a_i,b_i)\}$为某一小批量数据。典型的深度学习BP算法也即是使用SGD来更新模型参数的。

## 3.2 更多优化求解算法

### 3.2.1 使用ADMM求解稀疏学习问题

接下来，以稀疏学习为例进行优化求解分析。

令数据集$A \in \mathbb R^{N \times M}$为观测数据，
$b \in \mathbb R^{N}$ 为相应的标签。
在实际应用场景中，通常有$M \gg N$
稀疏学习假设模型参数是稀疏的，选取最为稀疏的模型，也即求解稀疏线性回归问题：

$
\min_{x \in \mathbb R^M} \left[ f(x) := \frac{1}{2} \|Ax-b\|^2 + \mu\|x\|_1\right].
\tag{prob-min}\label{prob-min}
$

可以使用变方向乘子法（ADMM）来求解 Prob. \eqref{prob-min}。
首先，引入附属变量$y$将原问题 Prob. \eqref{prob-min} 重新形式化为：

$
\begin{array}{ccl}
& \min_{x,y} & \frac{1}{2} \|Ax-b\|^2 + \mu\|y\|_1 \nonumber\\
& s.t. & y-x =0,
\end{array}
\tag{prob-min-xy}\label{prob-min-xy}
$

然后应用 ADMM 算法框架求解问题 Prob. \eqref{prob-min-xy}，算法可以描述为：


\begin{array}{cl}
x^{k+1} & := &\displaystyle \min_{x} \ \mathcal L_\beta\left(x,y^k,{\lambda}^k\right), \\\\ 
y^{k+1} & := &\displaystyle \min_{z} \ \mathcal L_\beta\left(x^{k+1},y,{\lambda}^k\right),\\\\ 
{\lambda}^{k+1} & := & {\lambda}^k - \beta\left(x^{k+1} - y^{k+1}\right),
\end{array}


其中，增广拉格朗日函数$\mathcal L_\beta(x,y,{\lambda})$定义为：

\[
\mathcal L_\beta\left(x,y,{\lambda}\right) = l(x) + \mu \|y\|_1 - \left\langle {\lambda}, x-y \right\rangle + \frac{\beta}{2}\left\|x-y\right\|^2.
\]

其中，$\lambda$是拉格朗日乘子， $\beta>0$ 是惩罚参数。
在该问题中，有解析表达式：

\begin{array}{c}
x^{k+1} = \left(\beta I + A^\top A \right)^{-1} \bullet \left[ A^\top b + \beta y^k -\lambda^k \right],
\end{array}


和

\begin{equation}
y^{k+1} = \text{sign} \left(x^{k+1}+\frac{\mu \lambda^k}{\beta} \right) \bullet \max \left( x^{k+1} + \frac{\mu \lambda^k}{\beta} -  \frac{\mu}{\beta}, 0  \right).
\end{equation}



### 3.2.2 使用更多优化算法求神经网络模型

从最优化的角度，神经网络也可以使用GD+BP之外的优化算法求解，比如ADMM。
使用ADMM求解神经网络，首先将神经网络形式化为优化问题，对于一个 $L$-layer 网络的训练任务可以形式化为关于 $(W_l), l\in[L]$ 的优化问题:
\begin{array}{cll}
&\displaystyle \min_{z, W, a} & loss(y,z_L)+ \displaystyle\sum_{l=1}^L R_l(W_l) &\\\\ 
& s.t. & z_l=W_l * a_{l-1},& l \in [L] \\\\ 
&& a_l=\sigma_l(z_l), & l\in [L-1].
\end{array}
上述问题可以等价变化为一个带约束条件的近似问题：
\begin{array}{cl}
\displaystyle \min_{z, W, a} & loss(y, z_L) + \displaystyle \sum_{l=1}^L R_l(W_l)  + 
\displaystyle  \frac{\rho}{2} \left(\sum_{l=1}^{L} \| z_l- W_l*a_{l-1}\|^2+ \sum_{l=1}^{L-1} \| a_l-\sigma_l(z_l)\|^2 \right).
\end{array}

然后，就可以使用ADMM、BCD等传统的优化算法求解神经网络模型了。

