---
layout: post
title: 知识图谱综述
comments: True
author: 高翊夫
---

作者：高翊夫

#### 1 Introduction
定义：将知识图视为旨在积累和传达现实世界知识的数据图，其节点表示感兴趣的实体，其边缘表示之间的关系。
核心是使用图形表示数据，通常通过某种方式显式表示知识
图模式的优势：

1.  边能补获实体间内在联系，而且针对不完整的信息补获
2. 专业图查询语言不仅支持标准关系运算符，还支持navigational operation以递归方式查找任意长度路径连接的实体。

以接下来几方面介绍：

* DATA GRAPHS：概述了图形数据模型和可用于查询它们的语言。
* Schema, Identity, Context:描述知识图中的模式，身份和上下文的表示。
* Deductive Knowledge:提出了演绎形式主义，可以用来代表和包含知识。
* Inductive Knowledge:描述了归纳技术，通过这些技术可以提取更多的知识。
* Creation and Enrichment:讨论了从外部来源创建和丰富知识图的问题。
* Quality Assesssment:列举了可以用来评估知识图的质量维度。
* Refinement:讨论了各种用于知识图细化的技术。
* ~~Publication:讨论发布知识图的原理和协议。~~
* Knowledge Graphs in Practice:调查一些著名的知识图及其应用。
* Summary and Conclusion:最后总结知识图谱和未来的研究方向。

根据智利旅游业相关的背景下提供了知识图谱具体示例。知识图由旅游业委员会管理，该委员会旨在增加该国的旅游业并在战略地区推广新景点。 知识图谱本身将最终描述旅游景点，文化活动，服务和业务，以及城市和城市间的旅行路线。
#### 2 Data Graphs
##### 2.1 Models
将旅游事件表示成以下关系模式：
$$
\text { Event(name, venue, type, start, end) }
$$

* name和start一起构成表的主键，以便唯一地标识重复发生的事件

* 问题；事件可能具有多个名称（例如，使用不同的语言），事件可能具有多个地点。每一次更新都需要进行昂贵的数据重新建模，重新加载和重新索引。

* **因此需要对实体间一组二元关系进行图形建模关系**，接下来介绍实践中应用到的三种图数据模型

###### 2.1.1 Directed edge-labelled graphs
有向边标记的图被定义为一组节点
![adb7b090ca5d8317676f671535fb6965](/figures/知识图谱综述.resources/A3E935FE-407A-4D2E-9F85-A68258F651A5.png)
和这些节点之间的一组有向标记的边，例如
:![acebd6569e7db33cffdad35242985e83](/figures/知识图谱综述.resources/1D037DCB-3B52-4010-BC65-939C9DDD4A21.png)
在知识图的情况下，节点用于表示实体，而边缘用于表示这些实体之间的（二元）关系。 下图提供了一个示例，说明旅游局如何将一些相关事件数据建模为有向边标记图
![cc682f9e8c3bd743f3170cc790c15096](/figures/知识图谱综述.resources/E5ACF33D-AF7F-4CF9-8A5D-CF90D35B7E42.png)
###### 2.1.2 Graph dataset
图数据集然后由一组命名图和一个默认图组成。每个命名图是一对图ID和一个图。图2提供了一个示例，其中事件和路线存储在两个命名图中，并且默认图管理有关命名图的元数据（不同图中的相同节点通常将引用同一实体，从而允许在合并图时集成该实体上的数据。）
![39efd8d0f99fef04e3c7ca93ccbab96e](/figures/知识图谱综述.resources/7F646886-AE65-4BEA-9884-D07D0B7477D9.png)
###### 2.1.3 Property graphs
引入属性图可为建模更复杂的关系提供更大的灵活性。 
例如整合提供有关公司提供哪种航班的票价的信息数据，对于有向边标记图
![e6ae4bb128df605e8cf4985bb823298b](/figures/知识图谱综述.resources/687B8712-CFE2-48B3-870E-69949CBA9865.png)
将此模型应用于图1中的所有数据将需要对以下内容进行重大更改
**属性图**允许将一组属性-值对和一个标签与节点和边关联。 图4提供了一个示例，再次显示了圣地亚哥和阿里卡之间以及提供这些路线的公司之间的航班
![1139af7e36d0a0db32ba3d5f78a04e1f](/figures/知识图谱综述.resources/6A88A00F-4B6F-40D4-B0C5-E112D114CB07.png)

###### 2.1.4 总结：
在图模型之间进行选择时，重要的是属性图可以转换为有向边标记的图和/或图数据集，也可以从中进行转换而不会丢失信息（例如，图4)。 总之，有向边标记图提供了更小的模型，而属性图提供了更灵活的模型。
##### 2.2 Querying
查询语言的基础是一些常见的原语，包括（基本）图模式，关系运算符，路径表达式等。
###### 2.2.1 Graph patterns
图的每种结构化查询语言的核心是（基本）图模式，其遵循与要查询的数据图相同的模型，另外还添加了变量。 因此，图形模式中的术语分为常量和变量，这些变量带有问号。
![d388a639ecb9d7750f4c6e4deb8c72ca](/figures/知识图谱综述.resources/A4519A65-7C30-405A-9491-AC075F857FB8.png)
用于评估图形模式的语义：

* 基于同态的语义
* 基于同构的语义：要求将节点和/或边缘上的变量映射到唯一项，因此从结果中排除了图5的后三个映射。
###### 2.2.2 Complex graph patterns
图模式将输入图转换为结果表（如图5所示）。然后，可以考虑使用关系代数来组合和/或变换此类表，从而根据一个或多个图形模式形成更复杂的查询。
![7a9e62536c67dffafebb63d63a23ddf2](/figures/知识图谱综述.resources/0B3E6334-6C88-45BE-9196-E2FFDAA9B93D.png)
###### 2.2.3 Navigational graph patterns.
导航图模式添加了路径表达式。
 路径表达式r是一个正则表达式，它允许匹配两个节点之间的任意长度的路径，这表示为正则路径查询$(x, r, y)$

*  其中x和y可以是变量或常量（甚至是相同的项） 

*  基本路径表达式是r为常数（边标记）的属性

举个例子，$(\text { Arica, bus } \star, \text { ?city })$与下图路径匹配
![2d0d4bef3e9918fdcdddf03510df8783](/figures/知识图谱综述.resources/D85971B6-FF40-4D9A-A434-C09957EA9D7D.png)
在图形模式中使用路径查询表示导航图形模式，该查询搜索从公共汽车或飞机从阿里卡可到达的城市的美食节。
![5232c79a1ded72909c3ec2166458d9c4](/figures/知识图谱综述.resources/7A79EDAB-00CB-4BFF-9B99-493E19043DAB.png)
#### 3 Schema, Identity, Context
为了解决这种多样性，模式，身份和上下文的表示通常起关键作用，模式定义了知识图的高级结构，身份表示图（或外部源）中的哪些节点引用相同的知识 现实世界中的实体，而上下文可能表示某个特定知识环境中的特定环境。
##### 3.1 Schema
###### 3.1.1 Semantic schema
>语义模式允许定义图中使用的高级术语（又名词汇或术语）的含义，这有助于使用这些术语对图进行推理。
>使用的类和属性之间定义子类，子属性，域和范围。 定义可以序列化为图形。  
![2165cb24ee492e1af41c7a6b0cda001c](/figures/知识图谱综述.resources/46FFD69B-2DE5-426F-9D42-77C42FE756C2.png)

适用于不完整的图数据信息：

* Closed World Assumption (CWA)
* Open World Assumption (OWA)
![4d7c3c501e63d7cec5f52663a071f058](/figures/知识图谱综述.resources/8AEBB8DB-CE31-4EF6-9BAC-3BBE3AEE815E.png)

###### 3.1.2 Validating schema

当使用图表示大规模的各种不完整数据时，OWA是默认语义的最合适选择。 我们可以在验证模式中定义约束，并针对生成的模式验证数据图，列出违反约束的情况。
>**Shapes（类似于UML的类图）**：A shape targets a set of nodes in a data graph and specifies constraints on those nodes.
![9ee7d08dc22dcff0086a63989d86ebfc](/figures/知识图谱综述.resources/805CBA12-4165-49A6-A77F-95E466B85B3E.png)

* 尽管验证模式和语义模式具有不同的目的，但它们可以相互补充。 

###### 3.1.3 Emergent schema(graph summary)
语义模式图和验证模式图都要求领域专家明确指定定义和约束。 但是，数据图通常会表现出潜在的结构，这些结构可以自动提取为紧急模式
>**quotient graphs**：partition groups of nodes in the data graph according to some equivalence relation while preserving some structural properties of the graph
![cafb59f8af47637e327f6f3c5db1f6c3](/figures/知识图谱综述.resources/E417BE2B-9F9D-4A75-915F-713FEE19BCE6.png)

* 根据数据等价关系对数据图中的节点组进行分区，同时保留图的某些结构特性。

##### 3.2 Identity
为了避免语义歧义，首先，可以使用全局唯一标识符来避免在使用外部数据扩展知识图时的命名冲突；其次，我们可以添加外部标识链接以相对于外部源消除节点的歧义
>语义冲突实例![6d69d1a4473efd9e9d321408c0ffeed7](/figures/知识图谱综述.resources/1452CE81-C000-40CD-943B-A23B60913F71.png)

###### 3.2.1 Global identifiers
使用国际化资源标识符（IRI）来标识诸如城市或事件之类的非信息[资源](https://www.wikidata.org/wiki/Property:P112)。
![6178720ff6b6b57d80763ada5f54a49a](/figures/知识图谱综述.resources/4E3280E0-7A64-445F-811A-EC45B53C9799.png)
###### 3.2.2 External identity links
虽然IRI能够避免命名冲突，但在不同的领域中也会有相同的标识同一实体。可以用如下边标识标识同一个实体的不同节点
![d6516e1a6c62e3f026675ae48019f138](/figures/知识图谱综述.resources/C686098D-3A06-4D56-91EE-2A93FF52FAF8.png)
###### 3.2.3 Datatypes
数据类型。 RDF数据中常用的其他数据类型包括xsd：string，xsd：integer，xsd：decimal，xsd：boolean等
###### 3.2.4 Existential nodes
 当对不完整的信息进行建模时，在某些情况下，我们可能知道图中必须存在一个特定的节点，该节点与其他节点具有特定的关系，但无法识别出该节点。
 ![954a62c370ec5f92223d53fa98ec2775](/figures/知识图谱综述.resources/FB453802-05CF-4989-A551-69B8E3EE58FD.png)
#### 4 DEDUCTIVE KNOWLEDGE
**“常识”**：以数据为前提，以及我们可能先验地了解一些关于世界的一般规则，我们可以使用演绎过程来得出新数据，从而使我们不仅可以了解数据明确给出的内容。
##### 4.1 Ontologies
>Ontologies是术语在其使用范围（例如，给定域）中的含义的具体形式表示。例如：其可以将一个事件可以正式定义一个实体，如果一个实体是一个“事件”，那么它恰好具有一个场所和恰好一个其开始的时刻。 相反，不同的事件本体可以定义一个“事件”可以具有多个场所和多个开始时间。

在实践中使用的最流行的ontology语言是与RDF图形兼容的Web Ontology Language（OWL）
###### 4.1.1 Interpretations
解释过程涉及将数据图中的节点和边映射到域图的节点和边。
>**域图**是由通过现实世界关系连接的现实世界实体组成的。
>数据图的**解释过程**由两个元素组成：域图，以及从数据图的项（节点和边标签）到域图的项的映射。 
>将节点映射成实体，将有向边映射成关系

![13f914af75216fe6a8f326fc39b538bb](/figures/知识图谱综述.resources/5D0E4275-D142-47B1-BFFB-62AC3176067A.png)![2ce727557ac88930cd4b8d263211121d](/figures/知识图谱综述.resources/6AD55A18-50E0-48A4-98A6-47119285A1C9.png)
域图作用：

* 根据不同的假设（CWA/OWA)，（UNA唯一名称假设/NUNA)，域图可以产生不同于数据图的更丰富关系
* 举例：在Arica和Viñadel Mar之间是否存在标记为“ flight”的边

这些假设定义了哪些解释有效，哪些解释满足哪些数据图。

* UNA禁止将两个数据项映射到同一域项的解释。 NUNA允许这种解释。 
* CWA下，在其域图中包含边的解释只能满足数据图， 在OWA中，包含边解释可以在数据图中没有出现，只要它不与该边矛盾即可。
* **OWL的情况下，采用了NUNA和OWA，代表了最一般的情况**
######  4.1.2 Individuals
![017144f0dcbd31b4b6633427b146175e](/figures/知识图谱综述.resources/E6DF25F6-194F-40F6-A090-6B341D731F90.png)
OWL支持的用于描述Individuals功能（个人理解是节点）
######  4.1.3 Properties 4.1.4 Classes
![5453fd41c06c5522a8054fbc8742ce1a](/figures/知识图谱综述.resources/904D6F92-E6FC-424E-A967-951D40F94FF4.png)![35473d5420db49e8ad708e3e23fdcc1b](/figures/知识图谱综述.resources/A9697349-5A06-4519-BB8C-93DFA47456B8.png)

##### 4.2 Reasoning
###### 4.2.1 Rules
> deductive knowledge is through inference rules
> a rule is composed of a body (if) and a head (then).

![14770e765c81203ef5d7235b9f9ff8d3](/figures/知识图谱综述.resources/9CE4118F-1DA3-43A3-9B3B-540511FEF950.png)
###### 4.2.2 Description Logics
>Description Logics are based on three types of elements: individuals, such as Santiago; classes (aka concepts) such as City; and properties (aka roles) such as flight.

![26bc3f48ae7887b2027d4faa2d060370](/figures/知识图谱综述.resources/CF6B1B6B-D009-4B21-BE07-C717D8EA6491.png)
![01ae6c0bf9cc2edc77391ea4e8f5ac97](/figures/知识图谱综述.resources/9D5DCA49-0285-476D-A3EE-5BD41353517E.png)
![2f57cf6e04d731cf3957038c03b4585f](/figures/知识图谱综述.resources/D23AC606-34AE-4925-B3BF-6DF11E3CBC32.png)
an airport is either a domestic airport or an international airport

*  描述逻辑（DL）最初是作为语义网络的方式而引入的。 考虑到语义网络是知识图的早期版本，并且DL已严重影响OWL，因此DL在知识图的逻辑形式化中占有重要地位。

#### 5 INDUCTIVE KNOWLEDGE

* 演绎知识的特征在于精确的逻辑结果
* 归纳式学习则涉及从一组给定的输入观测值中概括模式，然后将其用于生成新颖但可能不精确的预测
>几乎所有国家的首都都设有国际机场为他们服务，因此可以预测，如果圣地亚哥是首都，则很可能会有一个国际机场在为他们服务它;但是，从这种模式得出的预测并不确定

##### 5.1 Graph Analytics
>图分析是将分析过程应用于（通常是较大的）图数据。 图的性质自然地适合于某些类型的分析，这些分析基于图的拓扑即关于图的节点如何连接而得出关于节点和边的结论。 

![28f8099ce36976712bf8e85710586861](/figures/知识图谱综述.resources/FB83FA1E-56E0-4ABC-8321-38746B401A90.png)
###### 5.1.1 Techniques

* 中心度：旨在确定图的最重要（也称为中心）节点或边缘。 节点中心度度量将预测上图中的运输枢纽，而边缘中心度将使我们能够找到许多最短路线。
* 社区检测：旨在识别图中的社区，即与内部其他图形相比与内部图形连接更紧密的子图形。应用于上的社区检测可以检测到左侧（指的是智利北部），右侧（指的是智利南部），也可能是中心（指具有机场的城市）的社区。
* 连通性：旨在评估图形的连接程度。
* 节点相似性：旨在通过节点之间的连接方式查找与其他节点相似的节点。
###### 5.1.2 Frameworks
已经提出的用于大型图形分析的各种框架，通常是在分布式（集群）设置。
Apache Spark (GraphX) , GraphLab , Pregel , Signal–Collect , Shark 
工作流程：其中节点是可以沿着边缘向其他节点发送消息的处理器。 然后，计算是迭代的，在每个迭代中，每个节点读取通过向内边缘（可能还有其自己的先前状态）接收的消息，执行计算，然后根据结果通过向外的边缘发送消息。 

* 计算上图给定路线里最容易或最不容易到达的地点，可以选择PageRank，该函数可计算出游客在给定数量的“跳跃”之后随机遵循图中所示路线在特定位置的概率。
![ad13d495928199b2b8a6e8d8a92c301c](/figures/知识图谱综述.resources/01EFE296-1A93-4FC0-A29B-68B982BA40B4.png)

* In the message phase (Msg),每个节点在输出边上传递一个分数$\frac{d \mathrm{R}_{i}(v)}{|E(v)|}$，$d$是阻尼因子，代表游客随机调到任何地方的概率；$\mathrm{R}_{i}(v)$代表第i次迭代节点v的得分（游客在i跳后在节点v的概率），${|E(v)|}$代表每个节点的出度
* In the aggregation phase (Agg),每个节点计算入度分数之和，然后加$
\frac{1-d}{|V|}$，为下一次节点的初始分数

* 进入下一个迭代的消息阶段，一直持续到达到某种终止标准（例如，迭代计数或残差阈值等）并输出最终分数为止。
###### 5.1.3 Analytics with queries
考虑使用查询语言来投影或转换适合特定分析任务的图，例如从较大的数据图中提取图21的图。诸如SPARQL，Cypher和G-CORE之类的查询语言允许输出图，其中此类查询可用于选择要分析的子图。
##### 5.2 Knowledge Graph Embeddings
如何将图（或其节点，边等）编码为数字矢量？

1.  首先尝试one-hot编码，每个节点的嵌入维度为（图的节点数x图的边数）
* 这样的表示通常会导致向量大而稀疏，这对大多数机器学习模型都是效果不好的
2. 现在普遍的图嵌入分为实体嵌入（节点）和关系嵌入（边），维度一般是50-1000维

###### 5.2.1 Translational models
>转换模型将边缘标签解释为从主题节点（即源或头）到对象节点（即目标或尾）的转换

![ae28c5f5a7dcfbc8b2d64e6caf3d5acb](/figures/知识图谱综述.resources/88F60EE3-F15D-4D97-A75A-9B4EF09D83F8.png) TransE学习向量$e_{s},r_{p},e_{o}$使得前两个向量加起来尽可能与最后的向量接近
![9b9b677169e697f4e77887787629dacd](/figures/知识图谱综述.resources/9D8FA968-0F0B-41B6-BEAA-27E4D754F950.png)

* 上图是TransE计算的二维嵌入示例，使向量的方向与原始图形相似
* 预测图中的哪个节点最有可能在Antofagasta的西部。
###### 5.2.2 Tensor decomposition models
>利用矩阵分解的方法，降低参数量，得到嵌入模型

![59b2a23842d28ffd311107ed6fcf32e0](/figures/知识图谱综述.resources/DCC17AA8-72FE-483D-8818-D0B00DE44F95.png)

* one-hot 编码得到初始张量，大而稀疏，降维成为可行
* 利用CP分解方法计算出一系列向量$\left(\mathbf{x}_{1}, \mathbf{y}_{1}, \mathbf{z}_{1}, \dots, \mathbf{x}_{d}, \mathbf{y}_{d}, \mathbf{z}_{d}\right)$，d至少是原矩阵的秩
* 然后得到$X,Y,Z$矩阵分别由上面向量组成，每个行向量即为对应的嵌入

###### 5.2.3 Neural models
>先前讨论的方法都是线性关系，神经网络学习非线性关系的嵌入

1. Semantic Matching Energy (SME)：$f_{\mathbf{w}}\left(\mathbf{e}_{\mathbf{s}}, \mathbf{r}_{\mathbf{p}}\right)g_{\mathbf{w_{1}}}\left(\mathbf{e}_{\mathbf{s}}, \mathbf{r}_{\mathbf{p}}\right)$
学习这两个函数的参数，最终函数点乘得到一个可信的分数。
2. ConvE：将卷积核用到了模型中，卷积输入是源节点与边级联的向量，将卷积得到的特征向量经过线性层为d维的，最终与目标节点向量点乘得到可信分数
###### 5.2.4 Language models
>常用的语言模型有word2vector，glove，两种方法都基于大型文本集计算单词的嵌入，使得单词在相似的上下文里有相似的向量

RDF2Vec将随机游走在图上，并将路径（遍历的节点和边标记的序列）记录为“句子”，然后将其作为输入输入到word2vec模型中。
##### 5.3 Graph Neural Networks
>图神经网络基于数据图的拓扑结构构建神经网络。节点充当人工神经元，边充当加权连接。
>基于GNN的两种主要风格的主要思想-递归GNN和卷积GNN

* GNN输入是一个有向图，其节点和边都是由固定的特征向量组成（补获节点边权重信息，在训练过程中保持不变）
* 每个节点还有状态向量，可以根据邻居传递的信息进行递归更新（邻居节点的特征和状态向量，邻接边的特征向量）
* 状态向量的更新通过传播函数，输出函数计算出一个节点的最终输出

###### 5.3.1 Recursive graph neural networks
>举个例子，找到优先位置来建立新的旅游信息办公室。 最好的策略是将它们安装在许多游客可以从其到达热门目的地的枢纽中。
>可以试用递归GNN，直到到达固定点为止。

![aa509e3518cbfe8dea26665790a5ab70](/figures/知识图谱综述.resources/66B33958-E60A-40B0-A6EE-63EC803B58CA.png)

* 左图是子图，高亮的部分就是相邻节点；右图是函数更新过程
* n是特征向量，h是状态向量
* 为了训练网络，我们可以标记已经有旅游信息办公室的地方和没有的示例。 这些标签可以从知识图中获取，也可以手动添加。 然后，GNN可以学习参数w和w'，这些参数为标记的示例提供了预期的输出，随后可用于标记其他节点。

#### 6 CREATION AND ENRICHMENT
本节讨论了从多种多样的传统数据源（从纯文本到结构化格式，以及介于两者之间的内容）到创建知识图谱的过程。
##### 6.1 Text Sources
文本语料库（例如来自报纸，书籍，科学文章，社交媒体，电子邮件，网络抓取等的来源）是丰富信息的丰富来源。在下图中，我们说明了在示例句子上进行文本提取的四个核心任务。
![b9c0eeed8dab9fc2deddb899a8c733ac](/figures/知识图谱综述.resources/60F75245-6071-4F29-AC15-F8E07E4C6F65.png)

1. Pre-processing.预处理任务可能涉及对输入文本应用各种技术，其中上图所示为Tokenisation，它将文本解析为原子术语和符号。应用于文本语料库的其他预处理任务可能包括：
    * Part-of-Speech (POS) tagging：词性标记，用于标识表示动词，名词，形容词等的术语
    * Dependency Parsing：依赖解析，提取句子的语法树结构
    * Word Sense Disambiguation (WSD)：词性歧义消除

2. Named Entity Recognition (NER)：在文本中标识对命名实体的提及，通常以对人员，组织，位置以及可能的其他类型的提及为目标。
3. Entity Linking (EL)：将文本中提到的实体与目标知识图的现有节点相关联，目标知识图可以是正在创建的知识图，也可以是外部知识图。
4. Relation Extraction (RE)：RE任务提取文本中的实体之间的关系。最简单的情况是在封闭环境中提取二元关系。传统人工方法以及现代学习框架。

##### 6.2 Markup Sources
Web建立在链接标记文档的基础上，其中标记（也称为标签）用于分隔文档的元素（通常用于格式化）。 Web上的大多数文档都使用超文本标记语言（HTML）。下图是有关智利世界遗产的HTML网页示例：
![659368eb24f29fe15a08f5fa3d4adc4b](/figures/知识图谱综述.resources/4F73CA16-D2D0-4A18-BA7A-BC5F95F6D65D.png)
从标记文档中提取信息的一种方法是剥离标记（例如HTML标记），仅保留纯文本，然后利用上一节纯文本技术以创建和/或丰富知识图谱。
##### 6.3 Structured Sources
结构化数据包括：

* 以关系数据库为代表的表，CSV文件等形式
* 树状结构格式，例如JSON，XML等
* 与文本和标记文档不同：可以直接将结构化源文件映射到知识图，而不用提取内容再转化

###### 6.3.1 Mapping from tables
类似于数据库中概念图和关系数据表的转化
![699fbb436e26e4d38c38313e6183c876](/figures/知识图谱综述.resources/09C9A9FE-5629-4E7C-9AE6-FA7230B8CFDF.png)
![27d3d969d5669cf9673044e8d60b36b3](/figures/知识图谱综述.resources/20EB93F5-368E-4407-9D80-BB2ADECCAB37.png)
###### 6.3.2 Mapping from trees
GRDLL标准允许从XML映射到（RDF）图，而JSON-LD标准允许从JSON映射到（RDF）图。
#### 7 QUALITY ASSESSMENT

1. Accuracy：准确性是指实体和关系（由图形中的节点和边缘编码）在多大程度上正确表示现实生活中的现象。 准确性可以进一步细分为三个维度：语法准确性（数据类型），语义准确性和及时性。
2. Coverage：可以看做是完整性（特定数据集中所有必需信息的存在程度，确保查询是完整的）
3. Coherency：可以看做是知识图是否符合约束
4. Succinctness：简洁是指避免包含与领域无关的架构和数据元素。
#### 8 REFINEMENT

1. Completion：知识图的特点是不完整。 这样，知识图完成旨在填充知识图的缺失边缘（也称为缺失链接），即，被认为是正确的但是知识图既不给出也不包含的边缘。
    * 一般情况下，链接预测通常使用第5节讨论的归纳技术解决，特别是知识图嵌入和规则/公理挖掘。
    * 这种设置的主要挑战是效率，其中成对匹配将需要对n个节点进行$O(n^2)$比较。
2. Correction:与完成相反（在知识图中找到新的边缘），校正是识别并删除知识图中现有的不正确的边缘。 
    * 事实验证（又名事实检查）的任务涉及为事实/边缘分配合理性或真实性评分，通常在0到1之间。
    * 事实验证与链接预测之间存在明确的关系-两者都依赖于评估边缘/事实/链接的合理性。但是，事实验证通常考虑在线评估作为输入的给定边，而链接预测通常是离线任务，该任务会生成新的候选边以从知识图中进行评估。此外，事实验证工作的特点是考虑外部参考源，这些参考源可以是非结构化源或结构化源。
#### 10 KNOWLEDGE GRAPHS IN PRACTICE
1. Open Knowledge Graphs：开放意味着任何人都可以出于任何目的自由访问，使用，修改和共享（最多取决于保留来源和开放性的要求）
    * DBpedia、YAGO：大多是从Wikipedia / WordNet中提取的图
    * Freebase是人类知识的一般集合，从人类编辑那里征求文稿
 2. Enterprise Knowledge Graphs：改善搜索功能，提供用户推荐，实施对话/个人代理，增强目标广告，增强业务分析，连接用户，扩展多语言支持，促进研究和发现，评估和减轻风险，跟踪新闻事件，以及在（许多）其他方面提高运输自动化。
    *  Web search、Commerce、Social networks、Finance,etc.