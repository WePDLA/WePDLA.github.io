---
layout: post
mathjax: true
catalog: true
comments: true
top-tags-list: true
header-img: "img/post-bg-universe.jpg"
header-mask: 0.4
title: prompt
subtitle: 《Pre-train, Prompt, and Predict： A Systematic Survey of Prompting Methods in Natural Language Processing》阅读笔记
author: 阚志刚
tags: [NLP, 范式, prompt, 预训练]
---

# 一、 NLP领域的范式

如图1所示，这篇文章的作者认为目前自然语言处理领域存在四种范式：基于特征工程的全监督学习、基于架构工程的全监督学习、预训练-微调范式、预训练-prompt-预测范式。

{% include figure.html src="/figures/2022-02-18-prompt/4 paradigms.png" caption="图1：数据生成流程示意"%}

完全监督学习，即仅在目标任务的输入输出示例数据集上训练特定任务模型，长期以来在许多机器学习任务中发挥着核心作用，自然语言处理(NLP)也不例外。然而这种完全监督的数据集对于学习高质量的模型一直是不够的，早期的NLP模型严重依赖特征工程。

随着用于NLP的神经网络模型的出现，显著特征的学习与模型本身的训练结合在一起，因此重点转向了架构工程，研究重点更倾向于通过设计一个合适的网络架构，有利于学习这些特征。

然而，从2017-2019年开始，NLP模型的学习发生了翻天覆地的变化，这种完全监督的范式现在正在发挥越来越小的作用。这就是预训练-微调范式。这是一个具有固定架构的模型被预先训练为语言模型(LM)，预测观察到的文本数据的概率。通常做法是，先在大规模的数据集上使用特定任务进行预训练LM。然后，通过引入额外的参数，并使用特定任务的目标函数对它们进行微调，将上述预先训练的LM适应于不同的下游任务。在这个范例中，重点主要转向了目标工程。这种范式的思想是：先让模型在大规模数据集上学习目标语言的基本知识，然后针对特定下游任务微调这个模型。可以看做是让LM去迁就下游任务。

现在又出现了第四种范式————预训练-prompt-预测范式。在这个范例中，不是通过客观工程将预先训练的LM调整到下游任务，而是重新制定下游任务，使其看起来更像在原始LM训练中通过文本提示解决的那些任务。例如，当识别社交媒体帖子的情感色彩时，“I missed the bus today.”，我们可以通过在句子后面加上一个提示句子“I felt so __”，然后让LM用一个充满感情的词来填补这个空白，最后根据填写的这个词来看前面的句子是什么情感色彩。这种范式的思想是让下游任务去迁就LM。同过改变下游任务的形式，甚至可以不需要特定的训练就能让模型完成特定任务。


# 二、 prompt形式化

## 2.1 prompt相关术语
下面表格中是prompt范式中经常使用的一些术语。
{% include figure.html src="/figures/2022-02-18-prompt/prompt basic.png" caption="图2：prompt的一些术语"%}

## 2.2 prompt shape
1）根据提示符和待填空的字符z的位置，prompt又可以分类两类：cloze prompt 和 prefix prompt。
<strong>cloze prompt</strong>：待填充的字符z在提示字符中间。例：
情感分析任务：“X Overall, it was a Z movie.”.
<strong>prefix prompt</strong>：所有的提示字符都在待填充的字符z之前。例：
翻译任务：“Finnish: X English: Z”
2）提示字符不需要是真正的自然语言，也可以是一些虚拟的字符，比如表示字符的id或者是在连续空间生成的向量。
3）X和Z的数量可以灵活变化。

## 2.3 prompt的一些示例

{% include figure.html src="/figures/2022-02-18-prompt/examples of prompt.png" caption="图2：prompt在一些任务上的使用示例"%}


# 三、 个人经验

## 3.1 使用prompt范式解决问题

Prompt范式主要思想改变下游任务的形式，让下游任务来迁就预训练语言模型。我们在使用prompt范式来解决问题的时候首先要考虑如何将下游任务转换成预训练语言模型的训练子任务。在这个过程中，可以结合下游任务的特点和各个预训练语言模型的训练任务来考虑用哪个语言模型做工作。

## 3.2 prompt范式的性能

由于预训练语言模型已经在海量的数据上对子任务进行了训练，因此当下游任务被转换成某一个子任务的形式时，语言模型其实已经能在一定程度上解决这个任务了。因此使用prompt范式能够在零样本和小样本的场景下由较好的表现。
全监督场景下，其实prompt范式的性能还是比不上预训练-微调范式。不过也有可能是prompt范式还有很多技巧没有被开发出来，只是暂时在一些任务上落后于微调范式。
