---
layout: post
title: Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks
comments: True
author: liangpeng

---

作者：梁鹏

# Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks

arXiv:1802.04924v2 [cs.LG] 9 Jun 2018 

ICML2018

## Abstarct
目前的方法用一种并行策略（数据、模型）来将训练并行到多个设备上去。而这些策略的运行时间性能在大规模分布式训练中都是亚优化的，因为不同层可能需要不同的并行策略。在这篇文章中，我们提出layer-wise并行，来允许网络中每一层用individual的并行策略。我们通过解图搜索问题，来优化每一层应该如何并行。评估表明layer-wise并行比SOTA方法训练吞吐率高，通信开销少，可扩展性更高，且保持了原来网络的accuracy。

## 1. Introduction
数据并行、模型并行简介。全连接层喜欢模型并行，CNN喜欢数据并行。并且，有些层喜欢复杂的丙型策略，比如在混合的多维数据中并行（Section 3）。因此，对所有层 只使用一种并行策略时亚优化的。

这篇文章中提出了Layer-wise并行，使得每一层都可以用适合自己的 丙型策略。Layer-wise并行对于每一层来说计算都和原始的模型一样，因为保持原来的Accuracy。我们的做法定义了更加全面的并行策略搜索空间。我们的目标是保持原始网络accuracy的同时，为每一层找到合适的策略，达到最少的运行时间。为了形式化这个问题，我们引入*并行配置*，他定义了将一个层并行到多个设备上的搜索空间。

我们还提出了一个代价模型（cost model)，量化分析了不同并行策略运行时间。代价模型考虑了设备计算功耗，设备间通信带宽。利用代价模型，可以将选择并行策略的问题变为图搜索问题，并开发一个有效的算法去找到该代价模型下的全局最优策略。

我们用AlexNet，VGG-16，Inception-V3在ILSVRC 2012上评估了运行时间。用16张p100（4个结点）做分布式训练时,层级并行比SOTA策略快1.4-2.2倍。且该提速没有牺牲accuracy。并且，层级并行与数据和模型并行相比将通信量减少了1.3到23倍。最后，我们表明层级并行有更好的扩展性。将Inception-V3从1块GPUscale到16块时，有15.5倍加速，而其他并行策略最多只有11.2倍。

总结贡献：
- 提出层级并行，允许每一层有不同的并行配置
- 定义了并行配置搜索空间，并提出代价模型来量化分析运行时间。基于代价模型，我们开发了一个有效的算法来寻找最优并行策略
- 提出一个支持层级并行的实现，并表明和sota比，吞吐率有所提升，通信量有所下降，且提高了可扩展性。

## 2. Related Work
**数据和模型并行**
Krizhevsky数据并行(2012)，OWT(2014)。
Dean，模型并行(2012)
文章中用OWT作为baseline。

**System optimizations** [Goyal(2017)](https://arxiv.org/abs/1706.02677) 用3步allreduce操作来优化设备间通信，并且aggressively重叠了梯度同步和后向传播。
[Zhang(2017)](https://www.usenix.org/system/files/conference/atc17/atc17-zhang.pdf)介绍了一个混合通信scheme，来减少梯度同步的通信代价。所有这些系统都是基于数据并行，并且被通信代价所限制

**Network parameter reduction** [Han (2015)]()提出一种迭代权重剪枝方法，在去除弱连接的同时对网络进行重复训练。[Alvarez&Salzmann(2016)]()提出一种对每层冗余参数进行学习的网络，并对冗余参数进行迭代剔除。这些方法通过大量减少神经网络中的参数，减少了运行时间，但使得网络accuracy下降了（这些paper中有写出）。对比而言，这篇文章中的训练是和原网络一样的，因此不会损失精度。

## 3. Hidden Dimensions in Parallelizing a Layer
Tensor的其他维度也可以用来做并行，比如传统的2维图像CNN，有sample,height,width和channel。 

这些维度的任意组合都可以用来将一层并行化。我们应该考虑并行化训练时维度的选择，还有在每一个维度的并行度。探索这些额外的维度，有以下几点优势。

1. 减少执行时间，不同维度的并行，执行时间不一样，图1该层例子里的batch数据并行就不是最优解。
   {% include figure.html height="360" width="312" src="/figures/optcnn/1.png" caption="图1"%}
   
2. 减少通信开销。图二中展示的，将一个全连接层在两块GPU上采取不同维度的并行。数据并行（2a)中，每一块GPU在每一步都要完成整个层的梯度同步。另一种方法（2b)在channel维度进行并行，消灭了参数同步，因为不同的GPU训练不同子集的参数，但是带来了额外的input tensor的通信（阴影）。这个例子下，channel维度并行的通信量减少了12x.
  
  {% include figure.html height="360" width="312" src="/figures/optcnn/2.png" caption="图2"%}
   
3. 并行度(degree of parallelism/或者说并行设备数)影响运行时间。不同的层有着不同的执行时间和通信开销，因此可能偏好不同的并行度。图3表示了不同的并行度下Inception-v3中两层的运行时间。卷积层16块GPU时效果最好，全连接层则是4块。
{% include figure.html height="360" width="312" src="/figures/optcnn/3.png" caption="图3"%}


## 4. Problem Definition
用两张图来定义并行问题。第一张是*device graph*，建模了所有可获得的硬件设备和他们之间的连接关系。第二张图是*computation graph*，定义了要映射到*device graph*上的神经网络。

在设备图（device graph)$$\mathcal{D}$$中，每一个顶点$$d_i$$是一个设备（CPU或者GPU），每一条边$$(d_i,d_j)$$是两个设备的连接，通信带宽为$$b(d_i,d_j)$$。

在计算图$$\mathcal{G}$$中，顶点$$l_i \in \mathcal{G}$$是神经网络的一层，每一条边$$(l_i,l_j)\in \mathcal{G}$$ 是$$l_i$$的输出张量，$$l_j$$的输入张量。

现在我们定义一层的并行。为了将一层在多个设备上并行，假设不同的设备可以无依赖地并行处理该层。这要求不同的设备计算一层的输出向量的分离的各个部分。因此，我们通过定义输出张量的划分来描述一个层的并行化。

对于一层$$l_i$$，我们定义它的*parallelizable dimensions $$\mathcal{P_i}$$* 为它的输出tensor中可以被除的所有维度。比如对全连接层就是sample和channel，对于2D卷积就是sample,channnel,height和width。

一层$$l_i$$的并行配置$$c_i$$ 定义为$$l_i$$怎么被并行到不同的设备上去。对于$$\mathcal{P_i}$$中每一个可并行维度，$$c_i$$包括了一个正整数来描述在这一维度上的并行度。对于配置$$c_i$$，这些整数的乘积就是$$l_i$$这一层的总并行度。假设在每一个维度上，都是等量划分的，这样可以为多个设备提供平衡的工作负载。图4，展示了一些在4个设备上，可能的2D卷积层并行策略。
  {% include figure.html height="360" width="312" src="/figures/optcnn/4.png" caption="图4"%}

在一层上任意配置的并行都产生相同的输出，这保证了所有配置的并行训练和原模型一致，因此可维持一样的accuracy。

对每一层$$l_i\in \mathcal{G}$$，并行策略$$\mathcal{S}$$都有了一个对应的配置$$c_i$$。令$$t(\mathcal{G,D,S})$$为在设备图$$\mathcal{D}$$上采用并行策略$$\mathcal{S}$$时，并行化执行计算图$$\mathcal{G}$$一次迭代的时间。我们的目标是找到一个$$\mathcal{S}$$，使得$$t(\mathcal{G,D,S})$$最小。

## 5. Method
### 5.1 Cost Model
介绍了量化分析不同策略下运行时间的cost model，并且利用了基于*动态规划*的图搜索算法来找到代价模型下最优的并行策略。代价模型依赖于以下假设：
1. 对于层$$l_i \in \mathcal{G}$$，处理$$l_i$$的时间方差很小而且是可预测的，并且很大程度上独立于输入的数据的内容。
2. 对于带宽为$$b$$的每个连接$$(d_i,d_j)$$，从$$d_i$$到$$d_j$$传输大小为$$s$$的tensor，耗时为$$s/b$$。（即，通信带宽可以被完全利用）
3. 系统只有微不足道的overhead，即设备在一个层的输入tensor都到来之后就立刻开始执行，且设备已经完成之前的task。

大多数CNN层中的层都是基于稠密矩阵操作，他们的执行时间满足第一个假设。例外，实验也表明我们的实现满足第二和第三个假设。

我们在计算图上定义三个损失函数：
1. 对于每一个层$$l_i$$和它的并行配置$$c_i$$，$$t_c(l_i,c_i)$$是在配置$$c_i$$下处理层$$l_i$$的时间。这包括了前后向传播的时间。这个时间被估计为多次运行该配置的平均时间
2. 对于每个tensor $$e=(l_i,l_j),t_x(e,c_i,c_j)$$为将该tensor传输到目标设备的估计时间，用传输data大小和已知的通信带宽估计而来。
3. 对于每一层$$l_i$$和它的并行配置$$c_i$$，$$t_s(l_i,c_i)$$是在后向传播完成后同步$$l_i$$层参数的时间。为了完成参数同步，每个持有该层参数拷贝的设备需要传输他的局部梯度到参数服务器上。接收到梯度后，参数服务器将更新完的梯度重新传回给各设备。在这个过程中，参数更新的通信时间远比参数更新执行时间要长，因此我们用通信时间来近似参数同步时间。

使用以上3个代价函数，可定义
$$t_o(\mathcal{G,D,S})=\sum_{l_i\in \mathcal{G}}\{t_c(l_i,c_i)+t_s(l_i,c_i)\}+\sum_{e=(l_i,l_j)\in \mathcal{G}}t_x(e,c_i,c_j)\tag{1}$$
$$t_o(\mathcal{G,D,S})$$估计了采用策略$$\mathcal{S}$$时每一步的执行时间，包括了前向处理，后向传播和参数同步。

### 5.2   Graph Search
等式1表达了最优并行策略的寻找问题就是图的搜索问题：我们的目标就是找到策略$$\mathcal{S}$$使得总时间开销$$t_o(\mathcal{G,D,S})$$最小。

潜在的并行策略是层数的指数级，因此枚举所有策略时不现实的。不过，实际中CNN有很强的局部性：每一层只连接到在计算图中的几个有相似深度的层。基于这个观察，我们用下面两个图的剪枝来迭代优化计算图，同时保留最优并行策略。
  {% include figure.html height="360" width="312" src="/figures/optcnn/5.png" caption="图5"%}
**Node elimination.** 如果一个计算图中由一个节点$$l_j$$，他只有一条入边$$e_1=(l_i,l_j)$$和一条出边$$e_2=(l_j,l_k)$$，则将该节点和两条边从计算图中删掉，并插入一条新边$$e'=(l_i,l_k)$$回计算图。我们在保留最优并行策略的情况下定义$$t_x(e',·,·)$$：
$$t_x(e',c_i,c_k)\min_{c_j}\{t_c(l_j,c_j)+t_s(l_j,c_j)+t_x(e_1,c_i,c_j)+t_x(e_2,c_j,c_k)\} \tag{2}$$

直觉上，我们可以用动态规划来为所有$$c_i$$和$$c_k$$计算出节点$$l_j$$的最优配置$$c_j$$，并用和$$l_j$$关联代价函数来定义$$t_x(e',c_i,c_k)$$。

**Theorem 1.** 假设$$\mathcal{G'}=NodeElimination(\mathcal{G})$$，且$$l_j$$是被消除掉的顶点，如果$$S_o'$$是$$\mathcal{G'}$$的最优化并行策略，那么$$S_o = S_o'+c_j$$是$$\mathcal{G}$$的最优化并行策略，其中$$c_j$$最小化了公式2.

**Edge elimination.** 如果计算图$$\mathcal{G}$$包含两条有相同源和目的节点的边，$$e_1=(l_i,l_j)$$和$$e_2=(l_i,l_j)$$，则可以将$$e_1,e_2$$从图中消除，并插入新边$$e'=(l_i,l_j)$$到计算图中。我们用$$t_x(e_1,·,·)$$和$$t_x(e_2,·,·)$$来定义$$t_x(e',·,·)$$。
$$t_x(e',c_i,c_j)=t_x(e_1,c_i,c_j)+t_x(e_2,c_i,c_j)\tag{3}$$

**Theorem 2.** 假设$$\mathcal{G'}=EdgeElimination(\mathcal{G})$$，如果$$S_o'$$是$$\mathcal{G'}$$的最优化并行策略，那么$$S_o = S_o'$$是$$\mathcal{G}$$的最优化并行策略.

两条定理的证明略，在文章附录。

算法1展示了使用节点消除和边消除来寻找代价模型下最优并行策略的伪代码。算法先迭代地用节点消除和边消除来简化输入的计算图直到没有可以被消除的。图6解释了在一个Inception模块中他是怎么消除的。

Algorithm 1 Finding Optimal Parallelization Strategy S.
  {% include figure.html height="360" width="312" src="/figures/optcnn/a1.png" caption="算法1"%}

  {% include figure.html height="360" width="312" src="/figures/optcnn/6.png" caption="图6"%}

在完成消除之后，算法列举最终图中所有潜在策略，并选择使得$$t_o(\mathcal{G^{(m)},D,S^{(m)})}$$最小的 $${S^{(m)}}$$。然后通过反向顺序，决定消除节点的配置。定理1和2保证了$$S^{(i)}$$是$$\mathcal{G^{(i)}}$$的最优策略。最终$$S^{(0)}$$就是整个原始图的最优策略。

**Time complexity** 算法1的时间复杂度是$$O(EC^3+KC^K)$$，其中$$C$是对于一层来说最多的潜在配置。N和E分别是节点数目和边的数目，K是消除节点和边后的最终图。一般K=2，因为到最后只剩输入输出。

文章中还有表格，可以去看看。寻找最优解时对于Inception-V3，可以从>1天的时间缩短到0.4s

## 6. Experiments
发现在现有框架中，将一个层在多个维度并行都是很重要的，但是没有一个框架提供了控制这种粒度的并行的接口。因此在Legion中我们实现了自己的框架。Legion是一个分布式异构体系架构。我们用cuDNN和cuBLAS来作为下面的库来处理神经网络层。Legion的特征简化了我们的实现。首先，Legion支持高维划分，这允许我们将一个层在任意维度组合的并行。第二，Legion允许层等级粒度的并行。第三，Legion允许task和data的细粒度控制。第四，Legion的实现自动、系统地重叠了通信和计算，且优化了数据在及其中传输的路径和并行。

**Benchmarks.** AlexNet, VGG-16, Inception-V3

**Dataset.** ImageNet-1K

**Baselines.** 比较了以下4种并行：数据并行，模型并行，OWT并行，Layer-wise并行。

**Experimental setup.** 1个GPUcluster，4个计算节点。每一个都有2个Intel 10-core E5-2600，256G主内存，4个P100。GPU在同一个节点上用NVLink连接。节点间用100Gb/s的EDR infiniband连接。我们用同步训练，每个GPU上batch_size为32.

为了排除实现的区别，我们用TensorFlow r1.7, pytorch v 0.3以及我们的实现跑了数据并行，比较了运行时间。我们的Legion-based框架在3个CNN上和tf和torch相比都有最好的性能。因此我们用我们的框架报告了数据并行的性能。

### 6.1 Runtime Performance
  {% include figure.html height="360" width="312" src="/figures/optcnn/7.png" caption="图7"%}
layer-wise并行吞吐率在三个模型上在单节点上有2.2x,1.5x,1.4x的提升。

另外，扩展性也很好，在16个GPU上，layer-wise在三个模型上分别可达12.2x,14.8x,15.5x加速比。图7中还表明，layer-wise并行可以帮助弥补linear-scale的理想训练吞吐量(红线)与当前并行化策略实现的实际训练吞吐量之间的运行时性能差距。

通信代价在大规模训练中也很重要，图8比较了不同策略的通信代价。OWT比数据和模型并行能降低1.1-23.0x的通信代价。而Layer-wise则比OWT要再好1.2-2.5x。
  {% include figure.html height="360" width="312" src="/figures/optcnn/8.png" caption="图8"%}

### 6.2 Cost Model
估计执行时间和实际执行时间只相差了不到10%，说明代价模型可以有效预测CNN每一步的执行时间。

### 6.3 Analysis of Optimal Parallelization Strategies
分析了代价模型下的最优策略，找到了他们之间的一些相似性。

1. CNN开始的层，height/width很大，channel很小，此时最优化策略是在所有设备上利用数据并行，因为参数同步通信代价远比将tensor在层间移动小。
2. 更深的CNN层，height/width很小，channel很大。此时参数同步通信代价上升，tensor层间移动通信代价减少。此时的最优化策略时减少这些曾的运行设备，来减少参数同步的代价，同时适时地在height/width维度上使用并行，来达到更好的运行时间。
3. 对于全连接层，最优策略则变成了在几个设备上的模型并行，因为梯度同步和tensor的转移的通信代价都很高。这种做法可以减少同步参数的通信代价，且将移动tensor的代价变限制到所有设备的一个子集。

{% include figure.html height="360" width="312" src="/figures/optcnn/t5.png" caption="表5"%}
表5是在4块P100上的划分。可以看到开始的卷积层先用了sample维度的并行，然后后面的3层height/width维度上的并行。对于全连接层，用了channel维度的并行来减少通信代价，最适应性地减少并行度。

## 7. Conclusion
介绍了层级并行，允许每一层采用不同的并行策略。
提出了代价模型量化不同策略的运行时间，并基于动态编程做图搜索来找到代价模型下的全局最优策略。
实验表明层级并行比现有CNN训练的SOTA策略要更好。主要体现在训练吞吐量，通信代价减少，可扩展性上。
