---
layout: post
title: 华为双递归自动并行算法阅读笔记
comments: True
author: liangpeng

---

作者：梁鹏

#  华为双递归自动并行算法论文阅读笔记

EuroPar 2021 Efficient and Systematic Partitioning of Large and Deep Neural Networks for Parallelization

## 个人总结
这篇文章其实只考虑了op-level model parallelism的各种情况，其实现在还有多个其他维度的并行需要处理。

目前该算法已经在MindSpore库里面开源，而且近期也可以看到很多对该部分代码修改的痕迹。

个人看来这篇文章其实跟钱学海团队的AccPar有异曲同工之处，都是对算子进行hierarchical的划分。但是AccPar是支持异构架构的。不过这篇文章的双递归速度应该会比AccPar中的动态规划算法要更快一点。而且两者都没有做Pipeline的划分。

目前华为盘古大模型仍然属于半自动并行，没有它论文标题所提的那么玄乎。论文第10页最后两段指出在未来：1. 会设计一个cost model以及并行策略搜索算法来完全解放开发者在并行上的配置工作；2. 支持异构并行，并将tensor的一部分内存和计算offload到CPU上来加速训练（现在DeepSpeed在做的东西）；3. 使用Sparse Attention来加速计算（还是DeepSpeed在做的东西）。MindSpore现在抄作业的道路还有点长，还需要做自己的研究，需要极好的coding能力了。

## Abstarct
先前工作中，在合理总时间内找到有效的并行策略不是特别重要，但是这个预处理的时间还是很长，且生成的并行策略性能也不够高。这篇论文提出Flex-Edge Recursive Graph以及Double Recursive 算法，成功将并行策略生成时间变为了线性，且生成策略质量好。与OptCNN相比，搜索时间从小时降到了秒，且保持了一样的并行效率。

## 1. Introduction
DNN发展介绍，数据并行，模型并行，混合并行介绍（略）

这篇文章聚焦于如何选择高效的DNN混合并行策略。

FlexFLow不能保证搜索时长和最优性，OptCNN使用动态规划算法，并用profile技术和cost model来估计训练的全局执行时长。但是实际上算子的执行时间会跟DNN配置、以及数据集的变化而改变，其结果便是对模型或者数据集进行修改后需要执行新的profile和搜索。且这个多余的时间还不如直接用DP训练更划算。OptCNN里面的通信时长估计用的是数据量和通信bandwidth，然而通信容量还会跟延迟，网络拓扑等等有关系。单一带宽的选择会导致抉择出错。OptCNN的另一个缺点就是，其DP算法是被设计来处理fork-join图的，比如CNN，但是他处理不了多输入、多输出的图，比如常见于NLP，推荐系统和image segmentation的。

为了避免profile的问题，文章在第Sect.2介绍了基于每个算子的语义的purely symbolic 代价模型。在Sect.3中，观察到DNN里的都是多维矩阵，并受SGL启发，文章提出了2-part递归划分来消除机器通信容量的影响。另外，来提出FER Graph来降低搜索复杂度。利用DNN的特性，来使得FER Graph中的通信变得非拓扑依赖。文章根据节点的重要性来访问节点，来保证生成策略的质量。Sect.4中提出的双递归算法包括Inner递归和Outer递归。Inner递归用于将计算图分为两部分，Outer递归用于将Inner递归算法调度$$p$$次，来使得模型被分成$$2^p$$份。

## 2. Symbolic Cost Model
分布是并行程序的cost由局部计算代价和通信代价组成。局部计算是在每一个设备上进程内部，不考虑外部data的计算。通信则是设备之间的通信数据。算子在设备上都是同等条件下可高度并行的计算。因此，算子计算的次数，在给定的设备上对于任意分布式策略都是常数。深度学习框架允许计算操作在设备上的负载均衡，因此在给定设备数量时，通信代价对于任意的策略都是恒定的。因此，我们的渐进分析可以仅依赖于通信代价。

通信代价由两个因素决定：所选择机器的通信容量$$g$$，以及数据量$$q$$。为了达到更好的性能，现在的计算集群都是层级体系结构。单一的$$g$$不能用来准备描述集群机器的通信用量。Valiant提出不同层级要用不同的$$g$$。通信开销可以由各级通信量得以计算: $$Cost_{comm}=\sum_i{g_i \times q_i}$$，其中i为层级。作者发现这种层级结构是对齐的，因此受SGL启发，层级、对齐的集群可以用递归的方式进行抽象化。在每一步递归是层级树的某一级，其通信容量为$$g_i$$。对于每一级，$$g_i$$不影响丙型策略的选择。因此，通信可以被递归地分析，且通信总量为$$q_i$$，i为递归歩。

并行策略决定了Tensor在设备中怎么分布。文章将算子的输入输出张亮均匀分布在各个设备中来形式化他们的分析。因此并行策略的分析可以等同于通信量的分析。换一种方式来说，更少的通信总量意味着更好的并行策略。通信和计算的重叠技术与本文中的代价分析是正交的。目的：不管有无重叠技术，寻找最小的通信代价。

递归树中的每一级的分支取决于集群体系结构。但是设计太多的代价函数是不现实的。然而，每一级的递归树都是同构的，因此可以被变形为多级树。（4块GPU再分一级树，变成各两块GPU的层级结构。）通常用2的幂来实现效果可以达到最好。因此，递归树可以被转换成二叉树。

假设：假设所有设备正常operate，且忽略同种设备间小的性能差异。另外，对称结构的异构性也可被分解。

基于以上假设，同构性被应用于所有2-part分析中。

显然，可用p次递归的二分法来进行operator的划分。

DNN训练中由两种数据通信：算子内部的，算子间的。（略）

## 3. Flex-Edge Recursive Graph
定义了模型从算子级进行切分，Tensor有多少维就有多少种切分的策略。

### 3.2 定义了Flex-Edge Recursive Graph。
$$G_f = (\sigma(V),E)$$
$$\sigma_i(V) \in V$$是第$$i$$次被访问的节点的集合。 

### 3.3 Traversing Order
定义$$minCost$$函数，对比不同的策略的效果，从中选出最优的一个。函数将一个节点和他访问的边作为输入，然后搜索可能的划分维度，来寻找可以最优化通信代价的策略。

$$Cost(d_r, \sigma_i(V), \bar{E_i})=\min_{d\in \sigma_i(V)}.Type.D_p Cost(d, \sigma_i(V), \bar{E_i}) )$$

minCost返回该$$d_r$$。

## 4. Double Recursive Algorithm
Outer递归: p次二分法执行Inner递归，对Inner产生的图的节点Shape进行update。递归次数为设备数量$$N$$
Inner递归：输入：子图集合$$\mathcal{G}$$，当前图$$G_{f_in}$$。每一个step中，$$\mathcal{G}$$ Pop出一个子图$$G$$，其中的所有节点即将生成的策略是统一的，会用minCost进行选择，然后将更新的节点信息concat到输入的$$G_{f_in}$$中，再运行$$Inner(\mathcal{G}, G_{f_in}$$。递归运行直到所有的节点被访问位置。

## 5. Experiments
在GPU和Atlas 900 AI集群上进行了测试。与OptCNN相比，搜索时间大幅降低，且支持BERT模型的搜索。吞吐率与OptCNN旗鼓相当。


## Conclusion
优点：将搜索复杂度从指数级降低到了线性级，且可以应用于BERT等大模型。

缺陷：没有考虑inter-layer的划分（比如pipeline），所以可能得到亚优化策略。

未来可以做的东西：利用算子融合等技术来进行DNN加速，考虑寻找支持异构体系结构的方法。

