---
layout: post
mathjax: true
catalog: true
comments: true
top-tags-list: true
header-img: "img/post-bg-universe.jpg"
header-mask: 0.4
title: multimodal prompt
subtitle: 关于多模态prompt技术的调研
author: 阚志刚
tags: [多模态, prompt, 对比学习]
---

# 一、 CLIP

## 1.1 基本介绍
CLIP工作出自OpenAI团队，论文为《[Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf)》。


## 1.2 主要思想
{% include figure.html src="/figures/2022-03-01-多模态prompt/clip.png" caption="图1：CLIP的思想"%}

如图一所示，CLIP的主要思想是使用带有caption的图片作为训练数据，利用对比学习来预训练一个泛化性能更好的多模态模型。在进行下游任务的时候，使用NLP领域中prompt的思想，构建了一个带有空槽的句子，然后将标签内容填进去，形成一个关于标签的描述的句子。模型通过判断图片特征和每一个句子特征的相似度来判断样本最后的标签。


## 1.3 模型

### 1.3.1 预训练任务选择
{% include figure.html src="/figures/2022-03-01-多模态prompt/clip2.png" caption="图2：预训练任务对比"%}

本文的一个很大的贡献是提出了基于图文对利用对比学习来预训练。图二是作者分别使用“预测文本”、“预测文本的bag-of-words编码”和“用对比学习的方法来预测图文对”三种方式体现对比学习的效率。
“预测文本”的方法就是给定一张图片然后让模型逐字地预测整个文本，作者发现效果并不是很好。“预测文本的bag-of-words编码”是将文本便是为一个抽象的特征，然后给定一张图片，让模型去预测这个特征。相较于“预测文本”的方法，这个方法在达到相同准确率只用了三分之一的数据，即效率提升了3倍。“用对比学习的方法来预测图文对”（绿色线）是将模型的目标改为预测图片和文字是否配对，此时任务变得不那么难了。从图二中可以看出这种方法的训练效率又比“预测文本的bag-of-words编码”提升4倍。


### 1.3.2 预训练中的对比学习

{% include figure.html src="/figures/2022-03-01-多模态prompt/clip3.png" caption="图3：预训练中的对比学习"%}

图3是CLIP在预训练过程中的伪代码，我们可以看到作者先是对两个模态进行单独的编码，然后做一个线性变换（作者说这是让模型学习如何将特征从单模态变成多模态），接着就是计算单模态和多模态的余弦相似度。最后将logits与ground truth来比较计算loss。这里计算loss的方式是对比学习里比较常见的对称式的损失函数。

## 1.4 实验
这篇文章做了很多的实验，在这里不一一介绍，说几个我觉得有收获的地方：

### 1.4.1 可以prompt模板上再加一些约束

例如对于模板“It's a photo of {}, a type of animal.”，这样的话模型就会知道这是一种动物。

### 1.4.2 构建多个模板，最后归纳出一个更合理的结果

这篇文章构建了80个模板，综合这80个模板的输出，来得到最后的结果。

### 1.4.3 few-shot

直观上来说，一般few-shot的效果会比zero-shot效果好一点（毕竟能够看到几个样本），但是本文做了few-shot实验之后，发现了一些有趣的现象。

{% include figure.html src="/figures/2022-03-01-多模态prompt/clip4.png" caption="图4：few-shot实验"%}

这里是将CLIP的图片编码的结果拿出来做few-shot。蓝色线是SOTA工作之一。我们可以发现CLIP的zero shot的性能已经跟蓝线差不多了，十分强悍。

CLIP的zero-shot结果比1-shot，2-shot的效果都好。这其实证明了自然语言对图像任务的帮助是非常大的。

随着样本数量的增加，CLIP的效果更好了，这说明CLIP确实强。